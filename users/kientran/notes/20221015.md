## 1. Fourier transform:

**Audio signal** is represented by the intensity of air pressure at a certain time (remember how sound is longitudinal wave going through air). It can be represented by a numpy array of shape `(N,)`, where `N = audio_length_in_second * sample_rate`.

For example, a 5-second audio clip with a sample_rate of 16kHz would be represented by a numpy array of shape `(80000,)` where the first element is the air pressure intensity in the 1/16000 (s) timestamp.

**The fourier transform** is a way to decompose the original audio signal into sinwave's components.

- What kind of data is loss during Fourier transformation?
- What is its relationship to creating the spectrogram?

## 2. BirdNET

- What's are the key elements of their approach?
- What's the inputs and outputs of their pre-trained models?
